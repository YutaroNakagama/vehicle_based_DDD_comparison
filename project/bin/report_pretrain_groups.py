#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
report_pretrain_groups.py

Create a compact report for 10 vs 78 split using existing artifacts:
- Distance matrices (MMD / Wasserstein / DTW) and their subject order
- 10-subject groups generated by make_pretrain_groups.py (friendly/hard)

For each metric, computes:
  - Intra(T): mean pairwise distance within the 10-subject set T (i<j)
  - Inter(T,S): mean cross distance between T (10) and S (78)
  - NN(T→S): average nearest-neighbor distance from T to S

Outputs (per metric):
  misc/pretrain_groups/<metric>_report_ext.json  # numeric report
  misc/pretrain_groups/<metric>_report_ext.csv   # same as a 1-line CSV
  misc/pretrain_groups/<metric>_bars.png         # grouped bar chart (Intra/Inter/NN × Friendly/Hard)

Also writes a combined summary:
  misc/pretrain_groups/summary_report_ext.json
  misc/pretrain_groups/summary_report_ext.csv
"""

import os
import json
import argparse
from typing import List, Set, Tuple, Dict
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ---------- I/O helpers ----------

def load_matrix_subjects(matrix_path: str, subjects_path: str) -> Tuple[np.ndarray, List[str]]:
    M = np.load(matrix_path)
    with open(subjects_path, "r") as f:
        subs = json.load(f)
    if M.shape[0] != M.shape[1] or M.shape[0] != len(subs):
        raise ValueError(f"Matrix/subjects mismatch: {M.shape} vs {len(subs)}")
    np.fill_diagonal(M, 0.0)
    return M, subs

def load_group_ids(path_txt: str) -> List[str]:
    """Read one-line file: 10 IDs separated by spaces."""
    with open(path_txt, "r") as f:
        return f.read().strip().split()

def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)

def save_json(obj, path: str):
    ensure_dir(os.path.dirname(path))
    with open(path, "w") as f:
        json.dump(obj, f, indent=2)

# ---------- metrics on T vs S ----------

def intra_mean(M: np.ndarray, T: Set[int]) -> float:
    idx = list(T)
    if len(idx) < 2:
        return float("nan")
    vals = [M[i, j] for i in idx for j in idx if i < j]
    arr = np.array(vals, dtype=float)
    return float(np.nanmean(arr)) if arr.size else float("nan")

def inter_mean(M: np.ndarray, T: Set[int], S: Set[int]) -> float:
    if not T or not S:
        return float("nan")
    vals = [M[i, j] for i in T for j in S]
    arr = np.array(vals, dtype=float)
    return float(np.nanmean(arr)) if arr.size else float("nan")

def nn_T_to_S(M: np.ndarray, T: Set[int], S: Set[int]) -> float:
    """Average over t in T of min distance to S (NaN-safe)."""
    if not T or not S:
        return float("nan")
    S_list = list(S)
    mins = []
    for t in T:
        arr = np.array([M[t, s] for s in S_list], dtype=float)
        if arr.size:
            mins.append(np.nanmin(arr))
    return float(np.nanmean(mins)) if mins else float("nan")

# ---------- plotting ----------

def plot_bars(metric_name: str, stats: Dict[str, Dict[str, float]], out_png: str):
    """
    stats = {
      "friendly": {"intra": x, "inter": y, "nn": z},
      "hard":     {"intra": a, "inter": b, "nn": c}
    }
    """
    labels = ["Intra", "Inter", "NN"]
    friendly_vals = [stats["friendly"]["intra"], stats["friendly"]["inter"], stats["friendly"]["nn"]]
    hard_vals     = [stats["hard"]["intra"],     stats["hard"]["inter"],     stats["hard"]["nn"]]

    x = np.arange(len(labels))
    width = 0.36

    plt.figure(figsize=(7.5, 4.5))
    plt.bar(x - width/2, friendly_vals, width, label="Friendly")
    plt.bar(x + width/2, hard_vals,     width, label="Hard")
    plt.xticks(x, labels)
    plt.ylabel("Distance")
    plt.title(f"{metric_name.upper()}: Intra / Inter / NN (10 vs 78)")
    plt.legend()
    plt.tight_layout()
    ensure_dir(os.path.dirname(out_png))
    plt.savefig(out_png, dpi=180)
    plt.close()

# ---------- per-metric pipeline ----------

def report_for_metric(
    metric_name: str,
    matrix_path: str,
    subjects_path: str,
    group_dir: str
) -> Dict[str, Dict[str, float]]:
    M, subs = load_matrix_subjects(matrix_path, subjects_path)
    id2idx = {sid: i for i, sid in enumerate(subs)}

    g_friendly_path = os.path.join(group_dir, f"{metric_name}_friendly.txt")
    g_hard_path     = os.path.join(group_dir, f"{metric_name}_hard.txt")
    if not (os.path.exists(g_friendly_path) and os.path.exists(g_hard_path)):
        raise FileNotFoundError(f"Missing group files for {metric_name}: {g_friendly_path} / {g_hard_path}")

    ids_f = load_group_ids(g_friendly_path)
    ids_h = load_group_ids(g_hard_path)

    T_f = {id2idx[s] for s in ids_f if s in id2idx}
    T_h = {id2idx[s] for s in ids_h if s in id2idx}
    S_f = set(range(len(subs))) - T_f
    S_h = set(range(len(subs))) - T_h

    stats = {
        "friendly": {
            "intra": intra_mean(M, T_f),
            "inter": inter_mean(M, T_f, S_f),
            "nn":    nn_T_to_S(M, T_f, S_f),
            "ids":   [subs[i] for i in sorted(T_f)]
        },
        "hard": {
            "intra": intra_mean(M, T_h),
            "inter": inter_mean(M, T_h, S_h),
            "nn":    nn_T_to_S(M, T_h, S_h),
            "ids":   [subs[i] for i in sorted(T_h)]
        }
    }

    # Save per-metric artifacts
    out_dir = group_dir
    save_json(stats, os.path.join(out_dir, f"{metric_name}_report_ext.json"))

    # CSV: one line per (friendly/hard)
    df = pd.DataFrame.from_dict(stats, orient="index")[["intra","inter","nn"]]
    df.to_csv(os.path.join(out_dir, f"{metric_name}_report_ext.csv"))

    # Plot bars
    plot_bars(metric_name, stats, os.path.join(out_dir, f"{metric_name}_bars.png"))

    print(f"[{metric_name}] Intra/Inter/NN written and plotted.")
    return stats

# ---------- CLI ----------

def main():
    ap = argparse.ArgumentParser(description="Report Intra/Inter/NN for 10 vs 78 using pretrain groups.")
    ap.add_argument("--group_dir", default="misc/pretrain_groups", help="Directory containing <metric>_friendly.txt / _hard.txt")
    ap.add_argument("--out_summary_json", default="misc/pretrain_groups/summary_report_ext.json")
    ap.add_argument("--out_summary_csv",  default="misc/pretrain_groups/summary_report_ext.csv")
    args = ap.parse_args()

    metrics = [
        ("mmd",         "results/mmd/mmd_matrix.npy",               "results/mmd/mmd_subjects.json"),
        ("wasserstein", "results/distances/wasserstein_matrix.npy", "results/distances/subjects.json"),
        ("dtw",         "results/distances/dtw_matrix.npy",         "results/distances/subjects.json"),
    ]

    all_stats = {}
    for name, mpath, spath in metrics:
        print(f"== {name.upper()} ==")
        all_stats[name] = report_for_metric(name, mpath, spath, args.group_dir)

    # Write combined JSON
    save_json(all_stats, args.out_summary_json)

    # And combined CSV (rows: metric × (friendly/hard))
    rows = []
    for metric, st in all_stats.items():
        for kind in ["friendly","hard"]:
            rows.append({
                "metric": metric,
                "group": kind,
                "intra": st[kind]["intra"],
                "inter": st[kind]["inter"],
                "nn":    st[kind]["nn"]
            })
    pd.DataFrame(rows).to_csv(args.out_summary_csv, index=False)
    print(f"[OK] Wrote {args.out_summary_json} and {args.out_summary_csv}")

if __name__ == "__main__":
    main()

