# jobs/ directory

This directory contains **HPC job scripts** used to launch large-scale experiments on the cluster.  
Scripts are organized by purpose (preprocessing, training, evaluation, domain generalization).  

---

## Structure

```

jobs/
├── preprocess/       # Preprocessing pipelines (data preparation, feature extraction)
├── train/            # Training jobs (baseline, only10, finetuning, etc.)
├── evaluate/         # Evaluation jobs (metrics, ranking, quick evaluations)
├── domain_gen/       # Domain generalization jobs (e.g., CORAL, Mixup, VAE)
├── examples/         # Example PBS scripts (templates for new jobs)
├── log/              # PBS job logs (*.oXXXX, *.eXXXX)
└── README.md

````

---

## Notes
- Logs generated by PBS are stored under `jobs/log/`.  
- Most files here are **ignored by Git**, except this README and example templates.  
- Actual results are stored under:
  - `results/` → metrics, CSVs, NumPy arrays  
  - `models/` → trained models, scalers, feature metadata  

---

## Usage
Example submissions on the JAIST **KAGAYAKI** cluster:

```bash
# Run preprocessing
qsub jobs/preprocess/pbs_preprocess.sh

# Run training (10 random subjects)
qsub jobs/train/pbs_train_only10_random.sh

# Run evaluation
qsub jobs/evaluate/pbs_evaluate.sh

# Run domain generalization with CORAL
qsub jobs/domain_gen/pbs_pretrain_coral.sh
````

