# Vehicle-Based DDD Comparison

## Overview
This repository benchmarks **lightweight Driver Drowsiness Detection (DDD) models** using **vehicle-based features**.  
It compares the effectiveness and computational efficiency of multiple classical and neural ML models, with an emphasis on **domain generalization** across subjects.

The project provides:
- Preprocessing pipelines for EEG, vehicle dynamics, and physiological signals  
- Multiple ML models (classical + deep learning)  
- Feature selection and domain generalization techniques  
- HPC job scripts for large-scale experiments  
- Documentation (Sphinx, under `docs/`)  

---

## Dataset
We use the **open dataset** from *Multi-modal Data Acquisition Platform for Behavioral Evaluation* (Aygun et al., 2024):

- **Vehicle-based features**: steering angle, steering velocity, etc.  
- **EEG signals**  
- **Physiological signals**: GSR, blood pressure, heart rate, pupil size  
- **Annotations**: Karolinska Sleepiness Scale (KSS), vigilance state labels  

**DOI:** [10.7910/DVN/HMZ5RG](https://doi.org/10.7910/DVN/HMZ5RG)

```sh
curl -L -O -J "https://dataverse.harvard.edu/api/access/dataset/:persistentId/?persistentId=doi:10.7910/DVN/HMZ5RG"
```

---

## Directory Structure

```
├── bin/                  # Entry-point scripts (preprocess, train, evaluate, analyze)
├── data/                 # Data storage (not tracked, except README)
│   ├── interim/          # Intermediate cleaned data
│   ├── processed/        # Final datasets for modeling
│   └── README.md
├── docs/                 # Documentation (Sphinx, RST, HTML)
├── jobs/                 # HPC job scripts (PBS) organized by purpose
│   ├── preprocess/       # Preprocessing jobs
│   ├── train/            # Training jobs
│   ├── evaluate/         # Evaluation jobs
│   ├── domain_gen/       # Domain generalization jobs
│   ├── examples/         # PBS templates
│   └── log/              # PBS job logs (*.oXXXX, *.eXXXX)
├── misc/                 # Experiment configs & ad-hoc analysis scripts
│   ├── analysis/         # One-off analysis & plotting scripts
│   ├── config/           # Subject/group definitions, rank lists, requirements
│   └── README.md
├── models/               # Trained models & feature metadata (ignored except README)
├── reports/              # Reports, figures, tables for papers
│   └── figures/
├── results/              # Generated evaluation metrics/plots (ignored except README)
│   ├── analysis/
│   ├── distances/
│   ├── mmd/
│   ├── wasserstein/
│   └── ...
└── src/                  # Core source code
    ├── analysis/         # Distance metrics, correlation, summaries
    ├── data/             # Data utilities (checks, subject grouping)
    ├── data_pipeline/    # Preprocessing & feature extraction
    ├── evaluation/       # Evaluation framework
    ├── models/           # Model definitions & training pipelines
    └── utils/            # Shared helpers (domain gen, I/O, visualization)
```

---

## Installation

```bash
cd vehicle_based_DDD_comparison
pip install -r misc/config/requirements.txt
```

* Python 3.10 is recommended.
* For documentation build:

```bash
cd docs
pip install -r requirements.txt
make html
open _build/html/index.html
```

---

## Usage

### 1. Data Preprocessing

```bash
python bin/preprocess.py --model [common|SvmA|SvmW|Lstm] [--jittering]
```

### 2. Model Training

```bash
python bin/train.py \
    --model [RF|SvmA|SvmW|Lstm|BalancedRF|LightGBM|XGBoost|CatBoost|LogisticRegression|SVM|DecisionTree|AdaBoost|GradientBoosting|KNN|MLP] \
    [--domain_mixup] [--coral] [--vae] ...
```

### 3. Model Evaluation

```bash
python bin/evaluate.py --model RF [--subject_wise_split]
```

### 4. Analysis

```bash
python bin/analyze.py comp-dist --subject_list misc/config/subject_list.txt ...
```

---

## HPC Usage

Batch job scripts are provided in [`jobs/`](jobs/). Example:

```bash
# Preprocessing
qsub jobs/preprocess/pbs_preprocess.sh

# Training
qsub jobs/train/pbs_train_only10.sh

# Evaluation
qsub jobs/evaluate/pbs_evaluate.sh

# Domain generalization
qsub jobs/domain_gen/pbs_pretrain_coral.sh
```

Logs appear under `jobs/log/`.
Results will be saved in:

* `results/` (metrics, CSVs, NumPy arrays)
* `models/` (trained models, scalers, feature metadata)
* `reports/figures/` (visualizations)

---

## Documentation

Full documentation (generated by Sphinx) is under [`docs/`](docs/):

```bash
cd docs
make html
open _build/html/index.html
```

---

## References

1. Zhao et al. (2009) – Multiwavelet packet energy spectrum [DOI](http://dx.doi.org/10.1109/CISP.2009.5301253)
2. Arefnezhad et al. (2019) – Adaptive neuro-fuzzy selection on steering [DOI](https://doi.org/10.3390/s19040943)
3. Wang et al. (2022) – Vehicle dynamics + naturalistic driving [DOI](http://dx.doi.org/10.1016/j.trc.2022.103561)

