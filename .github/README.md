# Vehicle-Based DDD Comparison

## Overview
This repository benchmarks **lightweight Driver Drowsiness Detection (DDD) models** using **vehicle-based features**.  
It compares the effectiveness and computational efficiency of multiple classical and neural ML models, with an emphasis on **domain generalization** across subjects.

The project provides:
- Preprocessing pipelines for EEG, vehicle dynamics, and physiological signals
- Multiple ML models (classical + deep learning)
- Feature selection and domain generalization techniques
- HPC job scripts for large-scale experiments
- Documentation (Sphinx, under `docs/`)

---

## Dataset
We use the **open dataset** from *Multi-modal Data Acquisition Platform for Behavioral Evaluation* (Aygun et al., 2024):

- **Vehicle-based features**: steering angle, steering velocity, etc.
- **EEG signals**
- **Physiological signals**: GSR, blood pressure, heart rate, pupil size
- **Annotations**: Karolinska Sleepiness Scale (KSS), vigilance state labels

**DOI:** [10.7910/DVN/HMZ5RG](https://doi.org/10.7910/DVN/HMZ5RG)

```sh
curl -L -O -J "https://dataverse.harvard.edu/api/access/dataset/:persistentId/?persistentId=doi:10.7910/DVN/HMZ5RG"
````

---

## Directory Structure

```
├── docs/                  # Sphinx-based documentation (HTML, RST, etc.)
├── misc/                  # Utility scripts, subject lists, requirements
├── project/
│   ├── bin/               # Entry-point scripts (preprocess, train, evaluate, analyze)
│   ├── jobs/              # PBS job scripts & logs for HPC processing
│   └── src/               # Core source code
│       ├── analysis/      # Metrics, correlation, distance computations
│       ├── data_pipeline/ # Preprocessing & feature extraction
│       ├── evaluation/    # Evaluation pipeline
│       ├── models/        # Model architectures & feature selection
│       └── utils/         # Domain generalization, I/O, visualization helpers
├── results/               # Metrics, evaluation results
├── models/                # Trained models & feature selection metadata
├── figures/               # Visualization outputs
└── logs/                  # Logs from training/evaluation
```

---

## Installation

```bash
cd project
pip install -r misc/requirements.txt
```

* Python 3.10 is recommended.
* For documentation build:

  ```bash
  cd docs
  pip install -r requirements.txt
  make html
  open _build/html/index.html
  ```

---

## Usage

### 1. Data Preprocessing

```bash
python project/bin/preprocess.py --model [common|SvmA|SvmW|Lstm] [--jittering]
```

### 2. Model Training

```bash
python project/bin/train.py \
    --model [RF|SvmA|SvmW|Lstm|BalancedRF|LightGBM|XGBoost|CatBoost|LogisticRegression|SVM|DecisionTree|AdaBoost|GradientBoosting|KNN|MLP] \
    [--domain_mixup] [--coral] [--vae] ...
```

### 3. Model Evaluation

```bash
python project/bin/evaluate.py --model RF [--subject_wise_split]
```

### 4. Analysis

```bash
python project/bin/analyze.py comp-dist --subject_list misc/subject_list.txt ...
```

---

## HPC Usage

Batch job scripts are provided in [`project/jobs/`](project/jobs). Example:

```bash
cd project
qsub jobs/pbs_distance_pipeline.sh
qsub -J 1-6 jobs/pbs_only10_6groups.sh
```

Logs appear as `*.oXXXX` / `*.eXXXX` under `project/jobs/`.
Results will be saved under:

* `results/` (metrics, CSVs, NumPy arrays)
* `models/` (trained models, scalers, feature metadata)
* `figures/` (visualizations)
* `logs/` (runtime logs)

---

## Documentation

Full documentation (generated by Sphinx) is under [`docs/`](docs/):

```bash
cd docs
make html
open _build/html/index.html
```

---

## References

1. Zhao et al. (2009) – Multiwavelet packet energy spectrum [DOI](http://dx.doi.org/10.1109/CISP.2009.5301253)
2. Arefnezhad et al. (2019) – Adaptive neuro-fuzzy selection on steering [DOI](https://doi.org/10.3390/s19040943)
3. Wang et al. (2022) – Vehicle dynamics + naturalistic driving [DOI](http://dx.doi.org/10.1016/j.trc.2022.103561)


