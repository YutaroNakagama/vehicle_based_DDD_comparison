# Vehicle-Based DDD Comparison

## Overview
This repository benchmarks **lightweight Driver Drowsiness Detection (DDD) models** using **vehicle-based features**.  
It compares the effectiveness and computational efficiency of multiple classical and neural ML models, with an emphasis on **domain generalization** across subjects.

The project provides:
- Preprocessing pipelines for EEG, vehicle dynamics, and physiological signals
- Multiple ML models (classical + deep learning)
- Feature selection and domain generalization techniques
- HPC job scripts for large-scale experiments
- Documentation (Sphinx, under `docs/`)

---

## Dataset
We use the **open dataset** from *Multi-modal Data Acquisition Platform for Behavioral Evaluation* (Aygun et al., 2024):

- **Vehicle-based features**: steering angle, steering velocity, etc.
- **EEG signals**
- **Physiological signals**: GSR, blood pressure, heart rate, pupil size
- **Annotations**: Karolinska Sleepiness Scale (KSS), vigilance state labels

**DOI:** [10.7910/DVN/HMZ5RG](https://doi.org/10.7910/DVN/HMZ5RG)

```sh
curl -L -O -J "https://dataverse.harvard.edu/api/access/dataset/:persistentId/?persistentId=doi:10.7910/DVN/HMZ5RG"
````

---

## Directory Structure

```
├── bin/                  # Entry-point scripts (preprocess, train, evaluate, analyze)
├── data/                 # Data storage (not tracked, except README)
│   ├── raw/              # Original immutable data
│   ├── interim/          # Intermediate cleaned data
│   ├── processed/        # Final datasets for modeling
│   └── README.md
├── docs/                 # Documentation (Sphinx, RST, HTML)
├── jobs/                 # HPC job scripts & logs (ignored except README)
├── logs/                 # Runtime logs (ignored except README)
├── misc/                 # Utility scripts, configs, subject/group lists
├── models/               # Generated models & feature metadata (ignored except README)
├── reports/              # Final reports, figures, tables for papers
│   └── figures/
├── results/              # Generated evaluation metrics/plots (ignored except README)
└── src/                  # Core source code
    ├── analysis/
    ├── data_pipeline/
    ├── evaluation/
    ├── models/
    └── utils/

```

---

## Installation

```bash
cd project
pip install -r misc/requirements.txt
```

* Python 3.10 is recommended.
* For documentation build:

  ```bash
  cd docs
  pip install -r requirements.txt
  make html
  open _build/html/index.html
  ```

---

## Usage

### 1. Data Preprocessing

```bash
python project/bin/preprocess.py --model [common|SvmA|SvmW|Lstm] [--jittering]
```

### 2. Model Training

```bash
python project/bin/train.py \
    --model [RF|SvmA|SvmW|Lstm|BalancedRF|LightGBM|XGBoost|CatBoost|LogisticRegression|SVM|DecisionTree|AdaBoost|GradientBoosting|KNN|MLP] \
    [--domain_mixup] [--coral] [--vae] ...
```

### 3. Model Evaluation

```bash
python project/bin/evaluate.py --model RF [--subject_wise_split]
```

### 4. Analysis

```bash
python project/bin/analyze.py comp-dist --subject_list misc/subject_list.txt ...
```

---

## HPC Usage

Batch job scripts are provided in [`project/jobs/`](project/jobs). Example:

```bash
cd project
qsub jobs/pbs_distance_pipeline.sh
qsub -J 1-6 jobs/pbs_only10_6groups.sh
```

Logs appear as `*.oXXXX` / `*.eXXXX` under `project/jobs/`.
Results will be saved under:

* `results/` (metrics, CSVs, NumPy arrays)
* `models/` (trained models, scalers, feature metadata)
* `figures/` (visualizations)
* `logs/` (runtime logs)

---

## Documentation

Full documentation (generated by Sphinx) is under [`docs/`](docs/):

```bash
cd docs
make html
open _build/html/index.html
```

---

## References

1. Zhao et al. (2009) – Multiwavelet packet energy spectrum [DOI](http://dx.doi.org/10.1109/CISP.2009.5301253)
2. Arefnezhad et al. (2019) – Adaptive neuro-fuzzy selection on steering [DOI](https://doi.org/10.3390/s19040943)
3. Wang et al. (2022) – Vehicle dynamics + naturalistic driving [DOI](http://dx.doi.org/10.1016/j.trc.2022.103561)


